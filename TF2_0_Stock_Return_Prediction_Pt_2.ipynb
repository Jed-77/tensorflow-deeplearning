{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2.0 Stock Return Prediction Pt-2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgEu1F8YoJ/zh3OeO5+wZO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jed-77/tensorflow-deeplearning/blob/master/TF2_0_Stock_Return_Prediction_Pt_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRaBD1Ws9030",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, GRU, LSTM, Flatten, Dense, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju3n6FKZ9-nH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This model we will output prediction of up or down, rather than regression\n",
        "# ... of next day return. \n",
        "\n",
        "# Get the stock data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/tf2.0/sbux.csv')\n",
        "df['return'] = (df['close']-df['close'].shift(1))/df['close']\n",
        "input_data = df[['open', 'high', 'low', 'close', 'volume']].values\n",
        "targets = df['return'].values\n",
        "\n",
        "# Make the data for the neural network\n",
        "T = 10  # still considering time intervals of 10, predicting the 11th\n",
        "D = input_data.shape[1]   # using all 5 features (open, high, low, close, vol)\n",
        "N = len(input_data) - T  # the number of sampes \n",
        "\n",
        "# Normalise the inputs of training data\n",
        "Ntrain = len(input_data)*2//3\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(input_data[:Ntrain+T])\n",
        "input_data = scaler.transform(input_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey5Dra2X-3ML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare training data\n",
        "X_train = np.zeros((Ntrain, T, D))\n",
        "Y_train = np.zeros(Ntrain)\n",
        "for t in range(Ntrain):\n",
        "  X_train[t, :, :] = input_data[t:t+T]\n",
        "  Y_train[t] = (targets[t+T] > 0)\n",
        "\n",
        "# Prepare test  data\n",
        "X_test = np.zeros((N - Ntrain, T, D))\n",
        "Y_test = np.zeros(N - Ntrain)\n",
        "for u in range(N- Ntrain):\n",
        "  # u counts from 0 -> N-Ntrain, t counts from Ntrain->N\n",
        "  t = u+Ntrain\n",
        "  X_test[u, :, :] = input_data[t:t+T]\n",
        "  Y_test[u] = (targets[t+T]>0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hrgbbmeBjls",
        "colab_type": "code",
        "outputId": "7549662c-3e6a-4d87-f767-2df9be355f63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Build A Model\n",
        "i = Input(shape=(T,D))\n",
        "x = LSTM(50)(i)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(i, x)\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=Adam(lr=0.01),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "r = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=80,\n",
        "    validation_data=(X_test, Y_test)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.7006 - accuracy: 0.5101 - val_loss: 0.6961 - val_accuracy: 0.4902\n",
            "Epoch 2/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6957 - accuracy: 0.5113 - val_loss: 0.6938 - val_accuracy: 0.4927\n",
            "Epoch 3/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6915 - accuracy: 0.4970 - val_loss: 0.6928 - val_accuracy: 0.4829\n",
            "Epoch 4/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6919 - accuracy: 0.5221 - val_loss: 0.6911 - val_accuracy: 0.5317\n",
            "Epoch 5/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6901 - accuracy: 0.5411 - val_loss: 0.6909 - val_accuracy: 0.5293\n",
            "Epoch 6/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6899 - accuracy: 0.5328 - val_loss: 0.6955 - val_accuracy: 0.4878\n",
            "Epoch 7/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6913 - accuracy: 0.5328 - val_loss: 0.6913 - val_accuracy: 0.5293\n",
            "Epoch 8/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.5268 - val_loss: 0.6917 - val_accuracy: 0.5341\n",
            "Epoch 9/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6880 - accuracy: 0.5352 - val_loss: 0.6935 - val_accuracy: 0.5049\n",
            "Epoch 10/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.5268 - val_loss: 0.6934 - val_accuracy: 0.4976\n",
            "Epoch 11/80\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.6816 - accuracy: 0.5483 - val_loss: 0.6925 - val_accuracy: 0.4927\n",
            "Epoch 12/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6838 - accuracy: 0.5566 - val_loss: 0.6926 - val_accuracy: 0.5268\n",
            "Epoch 13/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6841 - accuracy: 0.5685 - val_loss: 0.6958 - val_accuracy: 0.5244\n",
            "Epoch 14/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6817 - accuracy: 0.5757 - val_loss: 0.6946 - val_accuracy: 0.5024\n",
            "Epoch 15/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6788 - accuracy: 0.5745 - val_loss: 0.6912 - val_accuracy: 0.5195\n",
            "Epoch 16/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6760 - accuracy: 0.5805 - val_loss: 0.6887 - val_accuracy: 0.5537\n",
            "Epoch 17/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6826 - accuracy: 0.5733 - val_loss: 0.6938 - val_accuracy: 0.5024\n",
            "Epoch 18/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6819 - accuracy: 0.5685 - val_loss: 0.6895 - val_accuracy: 0.5537\n",
            "Epoch 19/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6758 - accuracy: 0.5638 - val_loss: 0.6942 - val_accuracy: 0.4927\n",
            "Epoch 20/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6728 - accuracy: 0.5757 - val_loss: 0.6973 - val_accuracy: 0.4927\n",
            "Epoch 21/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6690 - accuracy: 0.5793 - val_loss: 0.6904 - val_accuracy: 0.5171\n",
            "Epoch 22/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6580 - accuracy: 0.6126 - val_loss: 0.6966 - val_accuracy: 0.5024\n",
            "Epoch 23/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6522 - accuracy: 0.5948 - val_loss: 0.6909 - val_accuracy: 0.5415\n",
            "Epoch 24/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6576 - accuracy: 0.5912 - val_loss: 0.6926 - val_accuracy: 0.5268\n",
            "Epoch 25/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6499 - accuracy: 0.6067 - val_loss: 0.7062 - val_accuracy: 0.5146\n",
            "Epoch 26/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6382 - accuracy: 0.6174 - val_loss: 0.6927 - val_accuracy: 0.5366\n",
            "Epoch 27/80\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.6280 - accuracy: 0.6222 - val_loss: 0.7020 - val_accuracy: 0.5317\n",
            "Epoch 28/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6175 - accuracy: 0.6198 - val_loss: 0.7051 - val_accuracy: 0.5073\n",
            "Epoch 29/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5988 - accuracy: 0.6341 - val_loss: 0.7087 - val_accuracy: 0.5049\n",
            "Epoch 30/80\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.6027 - accuracy: 0.6532 - val_loss: 0.7178 - val_accuracy: 0.4878\n",
            "Epoch 31/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6057 - accuracy: 0.6472 - val_loss: 0.7135 - val_accuracy: 0.4707\n",
            "Epoch 32/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5765 - accuracy: 0.6698 - val_loss: 0.7220 - val_accuracy: 0.4805\n",
            "Epoch 33/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5546 - accuracy: 0.7008 - val_loss: 0.7180 - val_accuracy: 0.4927\n",
            "Epoch 34/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5582 - accuracy: 0.6901 - val_loss: 0.7255 - val_accuracy: 0.5073\n",
            "Epoch 35/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5433 - accuracy: 0.7116 - val_loss: 0.7327 - val_accuracy: 0.4878\n",
            "Epoch 36/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5954 - accuracy: 0.6937 - val_loss: 0.7651 - val_accuracy: 0.4756\n",
            "Epoch 37/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6324 - accuracy: 0.6508 - val_loss: 0.7513 - val_accuracy: 0.4707\n",
            "Epoch 38/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5762 - accuracy: 0.6806 - val_loss: 0.7753 - val_accuracy: 0.4780\n",
            "Epoch 39/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5327 - accuracy: 0.7080 - val_loss: 0.8231 - val_accuracy: 0.5024\n",
            "Epoch 40/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5196 - accuracy: 0.7008 - val_loss: 0.7499 - val_accuracy: 0.4902\n",
            "Epoch 41/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4811 - accuracy: 0.7318 - val_loss: 0.8115 - val_accuracy: 0.4902\n",
            "Epoch 42/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4606 - accuracy: 0.7521 - val_loss: 0.8433 - val_accuracy: 0.4927\n",
            "Epoch 43/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4409 - accuracy: 0.7795 - val_loss: 0.8462 - val_accuracy: 0.4976\n",
            "Epoch 44/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4625 - accuracy: 0.7449 - val_loss: 0.9287 - val_accuracy: 0.4780\n",
            "Epoch 45/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4657 - accuracy: 0.7843 - val_loss: 0.8623 - val_accuracy: 0.4780\n",
            "Epoch 46/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4845 - accuracy: 0.7485 - val_loss: 0.8303 - val_accuracy: 0.5098\n",
            "Epoch 47/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4365 - accuracy: 0.7747 - val_loss: 0.8834 - val_accuracy: 0.4659\n",
            "Epoch 48/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.7890 - val_loss: 0.8661 - val_accuracy: 0.4902\n",
            "Epoch 49/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4055 - accuracy: 0.8188 - val_loss: 0.8896 - val_accuracy: 0.5122\n",
            "Epoch 50/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4285 - accuracy: 0.7843 - val_loss: 0.9129 - val_accuracy: 0.5024\n",
            "Epoch 51/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.8033 - val_loss: 0.9402 - val_accuracy: 0.4829\n",
            "Epoch 52/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4221 - accuracy: 0.7974 - val_loss: 0.9000 - val_accuracy: 0.4829\n",
            "Epoch 53/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3623 - accuracy: 0.8272 - val_loss: 0.9984 - val_accuracy: 0.4732\n",
            "Epoch 54/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.3346 - accuracy: 0.8498 - val_loss: 1.0705 - val_accuracy: 0.4780\n",
            "Epoch 55/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3957 - accuracy: 0.7962 - val_loss: 0.9820 - val_accuracy: 0.4512\n",
            "Epoch 56/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4216 - accuracy: 0.7795 - val_loss: 0.8499 - val_accuracy: 0.5171\n",
            "Epoch 57/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.3797 - accuracy: 0.8057 - val_loss: 0.8574 - val_accuracy: 0.4951\n",
            "Epoch 58/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.3301 - accuracy: 0.8415 - val_loss: 0.9028 - val_accuracy: 0.5293\n",
            "Epoch 59/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2871 - accuracy: 0.8796 - val_loss: 1.0544 - val_accuracy: 0.4756\n",
            "Epoch 60/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2980 - accuracy: 0.8749 - val_loss: 1.0264 - val_accuracy: 0.4927\n",
            "Epoch 61/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.3087 - accuracy: 0.8689 - val_loss: 1.2192 - val_accuracy: 0.4707\n",
            "Epoch 62/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2940 - accuracy: 0.8689 - val_loss: 1.1359 - val_accuracy: 0.4537\n",
            "Epoch 63/80\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2646 - accuracy: 0.8772 - val_loss: 1.1121 - val_accuracy: 0.4415\n",
            "Epoch 64/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2926 - accuracy: 0.8737 - val_loss: 1.0887 - val_accuracy: 0.4780\n",
            "Epoch 65/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2415 - accuracy: 0.8963 - val_loss: 1.1614 - val_accuracy: 0.4683\n",
            "Epoch 66/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2293 - accuracy: 0.9011 - val_loss: 1.1344 - val_accuracy: 0.5122\n",
            "Epoch 67/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2118 - accuracy: 0.9213 - val_loss: 1.2664 - val_accuracy: 0.4756\n",
            "Epoch 68/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3316 - accuracy: 0.8605 - val_loss: 1.2875 - val_accuracy: 0.5000\n",
            "Epoch 69/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4559 - accuracy: 0.8081 - val_loss: 1.2202 - val_accuracy: 0.4780\n",
            "Epoch 70/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3953 - accuracy: 0.8129 - val_loss: 0.9392 - val_accuracy: 0.4732\n",
            "Epoch 71/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.3696 - accuracy: 0.8296 - val_loss: 1.2025 - val_accuracy: 0.4659\n",
            "Epoch 72/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.3004 - accuracy: 0.8725 - val_loss: 1.1660 - val_accuracy: 0.4805\n",
            "Epoch 73/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2582 - accuracy: 0.9023 - val_loss: 1.0620 - val_accuracy: 0.5195\n",
            "Epoch 74/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2037 - accuracy: 0.9190 - val_loss: 1.1986 - val_accuracy: 0.4829\n",
            "Epoch 75/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.1963 - accuracy: 0.9321 - val_loss: 1.1712 - val_accuracy: 0.4659\n",
            "Epoch 76/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.1388 - accuracy: 0.9631 - val_loss: 1.2638 - val_accuracy: 0.4829\n",
            "Epoch 77/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.1127 - accuracy: 0.9726 - val_loss: 1.3918 - val_accuracy: 0.4805\n",
            "Epoch 78/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.1116 - accuracy: 0.9678 - val_loss: 1.5567 - val_accuracy: 0.4537\n",
            "Epoch 79/80\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.1047 - accuracy: 0.9654 - val_loss: 1.3478 - val_accuracy: 0.4927\n",
            "Epoch 80/80\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.1155 - accuracy: 0.9678 - val_loss: 1.4029 - val_accuracy: 0.4805\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}